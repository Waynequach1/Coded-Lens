import { TechnologyInfo } from "../../models/technology-info";

export const technologyExplanations: TechnologyInfo[] = [
    {
        technology: "Soap dispensers",
        body: "One of the most commonly overlooked biases in technology is soap dispensers. They exist everywhere and yet for a minority of people automatic soap dispensers don't work. This is because automatic soap dispensers rely on infared energy which gets absorbed more in darker people thus the machine is not able to pick up any infrared energy to dispense the soap."
    },
    {
        technology: "Facial Recognition",
        body: "Another super popular bias in technology is facial recognition. Many countries have already started enforcing use of this technology in widespread areas from simple beauty apps to use in security or even the surveillance of individuals. The major concern however is that facial recognition is inherently biased. These technologies use ai an feed it data on which it used to learn from the data however is mainly dominated by a white male sample size. As such people of color and women often get higher inaccuracies when using these technology. Further, the cross section of these minorties suffer most from this biased dataset with substantially higher inaccuracies then white males."
    },
    {
        technology: "Algorthims For Determining Employment",
        body: "Many companies have started using algorithms for hasing through potential employees. This is related to reducing hiring costs and saving time on the company's end. However, many of these algorithms contain potential biases. One example is amazon's hiring algorithm which learned based on successful applicants that female employees have less sustainability and in turn automatically declined every women that applied.",
    },
    {
        technology: "Chat Bots",
        body: "Chat bots that are designed simpliy for interacting and performing basic commands have biases too. Inherently, the developers of these chat bots are trained on biased data simiarily to facial recognition algorithms. As such, these chat bots have limitied capability when interacting with individuals outside of the majority group (white males) and aren't capable of understanding minority groups use of English (aka African-American Vernacular English or AAVE).",
    },
    {
        technology: "Crime Watch Algorithims",
        body: "What better way to capture criminals than to capture them the moment they act? This is why these algorithms were designed. Making use of incarceration rates and neighbourhood risk assessments, these algorithims attempt to predict where future crime would occur. However, these algorithims tend to target minority neighbourhoods in America due to the massive unbalance of racial incarcerations in America (With a massive majority being of darker skin color). These algorithims thus generate more crime and continue to feed into the cycle.",
    },
]